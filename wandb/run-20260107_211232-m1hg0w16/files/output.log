Started training at: 2026-01-07 21:12:34
============================================================================================
[PPO][begin] step=4000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.008/0.377/-5.530/+3.830 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%) | eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95 | w_progress=30 w_time=0.01 w_damage=0.05 w_not_actionable=0.01 w_acc=0.2 reward_clip=20 scaler_clip=5 terminal_bonus=3 terminal_fail_pen=3 | reward_scaling=0
[PPO][end]   step=4000 update_seconds=153.801
[PPO][begin] step=8000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.014/0.409/-7.580/+4.660 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%) | eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95 | w_progress=30 w_time=0.01 w_damage=0.05 w_not_actionable=0.01 w_acc=0.2 reward_clip=20 scaler_clip=5 terminal_bonus=3 terminal_fail_pen=3 | reward_scaling=0
[PPO][end]   step=8000 update_seconds=153.661
[PPO][begin] step=12000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.014/0.331/-5.900/+3.590 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%) | eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95 | w_progress=30 w_time=0.01 w_damage=0.05 w_not_actionable=0.01 w_acc=0.2 reward_clip=20 scaler_clip=5 terminal_bonus=3 terminal_fail_pen=3 | reward_scaling=0
[PPO][end]   step=12000 update_seconds=153.513
[PPO][begin] step=16000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.010/0.342/-3.250/+3.590 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%) | eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95 | w_progress=30 w_time=0.01 w_damage=0.05 w_not_actionable=0.01 w_acc=0.2 reward_clip=20 scaler_clip=5 terminal_bonus=3 terminal_fail_pen=3 | reward_scaling=0
[PPO][end]   step=16000 update_seconds=153.460
[PPO][begin] step=20000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.009/0.373/-4.090/+3.230 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%) | eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95 | w_progress=30 w_time=0.01 w_damage=0.05 w_not_actionable=0.01 w_acc=0.2 reward_clip=20 scaler_clip=5 terminal_bonus=3 terminal_fail_pen=3 | reward_scaling=0
[PPO][end]   step=20000 update_seconds=153.440
[PPO][begin] step=24000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.018/0.434/-5.420/+3.950 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%) | eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95 | w_progress=30 w_time=0.01 w_damage=0.05 w_not_actionable=0.01 w_acc=0.2 reward_clip=20 scaler_clip=5 terminal_bonus=3 terminal_fail_pen=3 | reward_scaling=0
[PPO][end]   step=24000 update_seconds=153.198
[PPO][begin] step=28000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.016/0.377/-5.020/+4.070 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%) | eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95 | w_progress=30 w_time=0.01 w_damage=0.05 w_not_actionable=0.01 w_acc=0.2 reward_clip=20 scaler_clip=5 terminal_bonus=3 terminal_fail_pen=3 | reward_scaling=0
[PPO][end]   step=28000 update_seconds=153.448
[PPO][begin] step=32000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.012/0.396/-3.490/+3.830 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%) | eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95 | w_progress=30 w_time=0.01 w_damage=0.05 w_not_actionable=0.01 w_acc=0.2 reward_clip=20 scaler_clip=5 terminal_bonus=3 terminal_fail_pen=3 | reward_scaling=0
[PPO][end]   step=32000 update_seconds=152.905
[PPO][begin] step=36000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.013/0.355/-3.850/+3.470 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%) | eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95 | w_progress=30 w_time=0.01 w_damage=0.05 w_not_actionable=0.01 w_acc=0.2 reward_clip=20 scaler_clip=5 terminal_bonus=3 terminal_fail_pen=3 | reward_scaling=0
[PPO][end]   step=36000 update_seconds=153.040
[PPO][begin] step=40000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.009/0.381/-4.210/+3.230 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%) | eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95 | w_progress=30 w_time=0.01 w_damage=0.05 w_not_actionable=0.01 w_acc=0.2 reward_clip=20 scaler_clip=5 terminal_bonus=3 terminal_fail_pen=3 | reward_scaling=0
[PPO][end]   step=40000 update_seconds=152.792
--------------------------------------------------------------------------------------------
saving model at: /root/libimmortal/./src/libimmortal/samples/PPO/checkpoints/PPO_ImmortalSufferingEnv_seed42_40000.pth
model saved
Elapsed Time: 1:13:56
--------------------------------------------------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
[PPO][begin] step=44000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.013/0.371/-5.020/+3.830 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%) | eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95 | w_progress=30 w_time=0.01 w_damage=0.05 w_not_actionable=0.01 w_acc=0.2 reward_clip=20 scaler_clip=5 terminal_bonus=3 terminal_fail_pen=3 | reward_scaling=0
[PPO][end]   step=44000 update_seconds=152.713
[PPO][begin] step=48000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.016/0.372/-5.020/+5.500 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%) | eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95 | w_progress=30 w_time=0.01 w_damage=0.05 w_not_actionable=0.01 w_acc=0.2 reward_clip=20 scaler_clip=5 terminal_bonus=3 terminal_fail_pen=3 | reward_scaling=0
[PPO][end]   step=48000 update_seconds=152.911
[PPO][begin] step=52000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.010/0.345/-3.610/+3.470 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%) | eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95 | w_progress=30 w_time=0.01 w_damage=0.05 w_not_actionable=0.01 w_acc=0.2 reward_clip=20 scaler_clip=5 terminal_bonus=3 terminal_fail_pen=3 | reward_scaling=0
[PPO][end]   step=52000 update_seconds=152.643
