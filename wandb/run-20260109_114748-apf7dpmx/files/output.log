Started training at: 2026-01-09 11:47:49
============================================================================================
[PPO][begin] step=212000 T=2000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.024/0.785/-10.020/+3.999 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%)
| eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95
| w_progress=100 w_time=0.01 w_damage=0.1 w_not_actionable=0.01 w_acc=1 reward_clip=20 scaler_clip=5
| reward_scaling=0
| bfs(mean/min/max)=0.6062/0.3480/0.8520 bfs_best=0.3480 bfs_delta_mean=0.00025 closer/farther=2.8%/2.8% bfs_missing=10.1%
[PPO][end]   step=212000 update_seconds=75.625
[PPO][begin] step=216000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.036/0.900/-12.010/+3.999 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%)
| eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95
| w_progress=100 w_time=0.01 w_damage=0.1 w_not_actionable=0.01 w_acc=1 reward_clip=20 scaler_clip=5
| reward_scaling=0
| bfs(mean/min/max)=0.3550/0.2760/0.4960 bfs_best=0.2760 bfs_delta_mean=-0.00002 closer/farther=3.0%/2.9% bfs_missing=7.1%
[PPO][end]   step=216000 update_seconds=151.028
[PPO][begin] step=220000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.039/0.926/-20.000/+3.999 goal_hits=0 (0.00%) shaper_clip_hits=1 (0.03%) scaler_clip_hits=0 (0.00%)
| eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95
| w_progress=100 w_time=0.01 w_damage=0.1 w_not_actionable=0.01 w_acc=1 reward_clip=20 scaler_clip=5
| reward_scaling=0
| bfs(mean/min/max)=0.6526/0.3120/0.7760 bfs_best=0.2760 bfs_delta_mean=-0.00002 closer/farther=3.0%/2.8% bfs_missing=7.1%
[PPO][end]   step=220000 update_seconds=151.154
[PPO][begin] step=224000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.039/0.910/-9.610/+3.999 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%)
| eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95
| w_progress=100 w_time=0.01 w_damage=0.1 w_not_actionable=0.01 w_acc=1 reward_clip=20 scaler_clip=5
| reward_scaling=0
| bfs(mean/min/max)=0.6867/0.6240/0.7720 bfs_best=0.2760 bfs_delta_mean=-0.00001 closer/farther=3.0%/2.9% bfs_missing=9.2%
[PPO][end]   step=224000 update_seconds=151.122
[PPO][begin] step=228000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.034/0.865/-11.620/+3.999 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%)
| eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95
| w_progress=100 w_time=0.01 w_damage=0.1 w_not_actionable=0.01 w_acc=1 reward_clip=20 scaler_clip=5
| reward_scaling=0
| bfs(mean/min/max)=0.6636/0.5200/0.7640 bfs_best=0.2760 bfs_delta_mean=-0.00000 closer/farther=2.8%/2.8% bfs_missing=9.2%
[PPO][end]   step=228000 update_seconds=151.147
[PPO][begin] step=232000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.032/0.899/-13.610/+3.999 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%)
| eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95
| w_progress=100 w_time=0.01 w_damage=0.1 w_not_actionable=0.01 w_acc=1 reward_clip=20 scaler_clip=5
| reward_scaling=0
| bfs(mean/min/max)=0.6765/0.5360/0.7960 bfs_best=0.2760 bfs_delta_mean=-0.00001 closer/farther=2.9%/2.8% bfs_missing=9.1%
[PPO][end]   step=232000 update_seconds=151.213
[PPO][begin] step=236000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.029/0.896/-10.410/+3.999 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%)
| eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95
| w_progress=100 w_time=0.01 w_damage=0.1 w_not_actionable=0.01 w_acc=1 reward_clip=20 scaler_clip=5
| reward_scaling=0
| bfs(mean/min/max)=0.6840/0.6240/0.7640 bfs_best=0.2760 bfs_delta_mean=0.00001 closer/farther=3.1%/2.7% bfs_missing=7.6%
[PPO][end]   step=236000 update_seconds=151.167
[PPO][begin] step=240000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.050/1.008/-20.000/+3.999 goal_hits=0 (0.00%) shaper_clip_hits=1 (0.03%) scaler_clip_hits=0 (0.00%)
| eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95
| w_progress=100 w_time=0.01 w_damage=0.1 w_not_actionable=0.01 w_acc=1 reward_clip=20 scaler_clip=5
| reward_scaling=0
| bfs(mean/min/max)=0.6697/0.5200/0.7960 bfs_best=0.2760 bfs_delta_mean=0.00000 closer/farther=2.7%/3.2% bfs_missing=9.9%
[PPO][end]   step=240000 update_seconds=151.179
--------------------------------------------------------------------------------------------
saving model at: /root/libimmortal/src/libimmortal/samples/PPO/checkpoints/PPO_ImmortalSufferingEnv_seed42_240000.pth
model saved
Elapsed Time: 0:45:06
--------------------------------------------------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
[PPO][begin] step=244000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.036/0.876/-12.820/+3.999 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%)
| eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95
| w_progress=100 w_time=0.01 w_damage=0.1 w_not_actionable=0.01 w_acc=1 reward_clip=20 scaler_clip=5
| reward_scaling=0
| bfs(mean/min/max)=0.6589/0.5400/0.7560 bfs_best=0.2760 bfs_delta_mean=-0.00001 closer/farther=2.9%/2.9% bfs_missing=8.3%
[PPO][end]   step=244000 update_seconds=151.126
[PPO][begin] step=248000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.025/0.833/-11.210/+3.999 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%)
| eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95
| w_progress=100 w_time=0.01 w_damage=0.1 w_not_actionable=0.01 w_acc=1 reward_clip=20 scaler_clip=5
| reward_scaling=0
| bfs(mean/min/max)=0.3777/0.2760/0.6400 bfs_best=0.2760 bfs_delta_mean=0.00009 closer/farther=3.0%/2.6% bfs_missing=7.0%
[PPO][end]   step=248000 update_seconds=151.129
[PPO][begin] step=252000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.018/0.748/-7.610/+3.999 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%)
| eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95
| w_progress=100 w_time=0.01 w_damage=0.1 w_not_actionable=0.01 w_acc=1 reward_clip=20 scaler_clip=5
| reward_scaling=0
| bfs(mean/min/max)=0.3344/0.2720/0.3920 bfs_best=0.2720 bfs_delta_mean=-0.00000 closer/farther=2.9%/3.0% bfs_missing=9.6%
[PPO][end]   step=252000 update_seconds=151.171
[PPO][begin] step=256000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.036/0.828/-11.210/+3.999 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%)
| eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95
| w_progress=100 w_time=0.01 w_damage=0.1 w_not_actionable=0.01 w_acc=1 reward_clip=20 scaler_clip=5
| reward_scaling=0
| bfs(mean/min/max)=0.3668/0.2840/0.6720 bfs_best=0.2720 bfs_delta_mean=-0.00007 closer/farther=2.8%/2.9% bfs_missing=5.8%
[PPO][end]   step=256000 update_seconds=151.101
[PPO][begin] step=260000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.038/0.906/-16.820/+3.999 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%)
| eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95
| w_progress=100 w_time=0.01 w_damage=0.1 w_not_actionable=0.01 w_acc=1 reward_clip=20 scaler_clip=5
| reward_scaling=0
| bfs(mean/min/max)=0.6522/0.5120/0.8000 bfs_best=0.2720 bfs_delta_mean=-0.00002 closer/farther=2.7%/2.9% bfs_missing=9.9%
[PPO][end]   step=260000 update_seconds=151.210
[Exit] stop requested -> saving final checkpoint: /root/libimmortal/src/libimmortal/samples/PPO/checkpoints/PPO_ImmortalSufferingEnv_seed42_262206.pth
Final model saved at: /root/libimmortal/src/libimmortal/samples/PPO/checkpoints/PPO_ImmortalSufferingEnv_seed42_262206.pth