{"train/reward_mean": -0.019999999552965164, "train/reward_min": -0.019999999552965164, "train/reward_max": -0.019999999552965164, "train/raw_reward_mean": 0.0, "train/raw_reward_min": 0.0, "train/raw_reward_max": 0.0, "train/done_frac": 0.0, "train/done_env_frac": 0.0, "train/is_goal_frac": 0.0, "train/virtual_done_frac": 0.0, "train/episode_reward_running_mean": -0.02, "train/episode_reward_running_max": -0.02, "train/episode_len_running_mean": 1.0, "train/episode_len_running_max": 1.0, "_timestamp": 1768194315.400182, "_runtime": 855.8453950881958, "_step": 962000, "train/updated": 1, "train/update_seconds": 152.6907548904419, "train/step": 962000, "train/global_env_steps": 3848000, "train/update_goal_hits": 0, "train/update_terminals": 0, "train/update_shaper_clip_hits": 14, "train/update_scaler_clip_hits": 0, "rollout/horizon": 2000, "rollout/envs_per_rank": 2}