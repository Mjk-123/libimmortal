Started training at: 2026-01-08 23:40:00
============================================================================================
[PPO][begin] step=164000 T=3779 terminals=0 (0.00%) reward(mean/std/min/max)=-0.032/0.881/-10.410/+3.999 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%)
| eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95
| w_progress=100 w_time=0.01 w_damage=0.1 w_not_actionable=0.01 w_acc=1 reward_clip=20 scaler_clip=5
| reward_scaling=0
| bfs(mean/min/max)=0.6718/0.3680/0.8520 bfs_best=0.3680 bfs_delta_mean=0.00013 closer/farther=2.8%/2.9% bfs_missing=9.3%
[PPO][end]   step=164000 update_seconds=143.990
[PPO][begin] step=168000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.058/1.054/-16.820/+3.999 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%)
| eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95
| w_progress=100 w_time=0.01 w_damage=0.1 w_not_actionable=0.01 w_acc=1 reward_clip=20 scaler_clip=5
| reward_scaling=0
| bfs(mean/min/max)=0.3910/0.1520/0.5760 bfs_best=0.1520 bfs_delta_mean=-0.00002 closer/farther=3.0%/2.9% bfs_missing=3.8%
[PPO][end]   step=168000 update_seconds=151.510
[PPO][begin] step=172000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.037/0.905/-13.220/+3.999 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%)
| eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95
| w_progress=100 w_time=0.01 w_damage=0.1 w_not_actionable=0.01 w_acc=1 reward_clip=20 scaler_clip=5
| reward_scaling=0
| bfs(mean/min/max)=0.3672/0.2120/0.4880 bfs_best=0.1520 bfs_delta_mean=0.00004 closer/farther=2.9%/2.8% bfs_missing=3.8%
[PPO][end]   step=172000 update_seconds=151.464
[PPO][begin] step=176000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.024/0.743/-7.610/+3.999 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%)
| eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95
| w_progress=100 w_time=0.01 w_damage=0.1 w_not_actionable=0.01 w_acc=1 reward_clip=20 scaler_clip=5
| reward_scaling=0
| bfs(mean/min/max)=0.3419/0.2520/0.4840 bfs_best=0.1520 bfs_delta_mean=0.00000 closer/farther=2.9%/2.9% bfs_missing=9.2%
[PPO][end]   step=176000 update_seconds=151.336
[PPO][begin] step=180000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.030/0.811/-10.020/+3.999 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%)
| eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95
| w_progress=100 w_time=0.01 w_damage=0.1 w_not_actionable=0.01 w_acc=1 reward_clip=20 scaler_clip=5
| reward_scaling=0
| bfs(mean/min/max)=0.3440/0.2760/0.4720 bfs_best=0.1520 bfs_delta_mean=-0.00001 closer/farther=3.0%/2.7% bfs_missing=2.9%
[PPO][end]   step=180000 update_seconds=151.436
[PPO][begin] step=184000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.023/0.758/-10.420/+3.999 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%)
| eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95
| w_progress=100 w_time=0.01 w_damage=0.1 w_not_actionable=0.01 w_acc=1 reward_clip=20 scaler_clip=5
| reward_scaling=0
| bfs(mean/min/max)=0.3351/0.2720/0.4880 bfs_best=0.1520 bfs_delta_mean=-0.00004 closer/farther=3.0%/2.6% bfs_missing=4.6%
[PPO][end]   step=184000 update_seconds=151.317
[PPO][begin] step=188000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.056/0.949/-14.020/+3.999 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%)
| eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95
| w_progress=100 w_time=0.01 w_damage=0.1 w_not_actionable=0.01 w_acc=1 reward_clip=20 scaler_clip=5
| reward_scaling=0
| bfs(mean/min/max)=0.6295/0.3040/0.7680 bfs_best=0.1520 bfs_delta_mean=-0.00005 closer/farther=2.8%/3.0% bfs_missing=4.7%
[PPO][end]   step=188000 update_seconds=151.427
[PPO][begin] step=192000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.029/0.819/-10.410/+3.999 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%)
| eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95
| w_progress=100 w_time=0.01 w_damage=0.1 w_not_actionable=0.01 w_acc=1 reward_clip=20 scaler_clip=5
| reward_scaling=0
| bfs(mean/min/max)=0.6905/0.6120/0.7760 bfs_best=0.1520 bfs_delta_mean=-0.00000 closer/farther=2.9%/2.9% bfs_missing=4.8%
[PPO][end]   step=192000 update_seconds=151.547
[PPO][begin] step=196000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.031/0.833/-10.410/+3.999 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%)
| eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95
| w_progress=100 w_time=0.01 w_damage=0.1 w_not_actionable=0.01 w_acc=1 reward_clip=20 scaler_clip=5
| reward_scaling=0
| bfs(mean/min/max)=0.6567/0.5160/0.8160 bfs_best=0.1520 bfs_delta_mean=0.00002 closer/farther=2.8%/2.9% bfs_missing=8.9%
[PPO][end]   step=196000 update_seconds=151.358
[PPO][begin] step=200000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.032/0.892/-11.210/+3.999 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%)
| eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95
| w_progress=100 w_time=0.01 w_damage=0.1 w_not_actionable=0.01 w_acc=1 reward_clip=20 scaler_clip=5
| reward_scaling=0
| bfs(mean/min/max)=0.6773/0.5360/0.7720 bfs_best=0.1520 bfs_delta_mean=0.00002 closer/farther=3.0%/2.7% bfs_missing=5.3%
[PPO][end]   step=200000 update_seconds=151.226
--------------------------------------------------------------------------------------------
saving model at: /root/libimmortal/src/libimmortal/samples/PPO/checkpoints/PPO_ImmortalSufferingEnv_seed42_200000.pth
model saved
Elapsed Time: 0:59:48
--------------------------------------------------------------------------------------------
[34m[1mwandb[39m[22m: [33mWARNING[39m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
[PPO][begin] step=204000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.049/1.053/-20.000/+3.999 goal_hits=0 (0.00%) shaper_clip_hits=2 (0.05%) scaler_clip_hits=0 (0.00%)
| eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95
| w_progress=100 w_time=0.01 w_damage=0.1 w_not_actionable=0.01 w_acc=1 reward_clip=20 scaler_clip=5
| reward_scaling=0
| bfs(mean/min/max)=0.6269/0.3240/0.7600 bfs_best=0.1520 bfs_delta_mean=-0.00002 closer/farther=2.9%/2.9% bfs_missing=5.8%
[PPO][end]   step=204000 update_seconds=151.173
[PPO][begin] step=208000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.032/0.860/-11.610/+3.999 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%)
| eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95
| w_progress=100 w_time=0.01 w_damage=0.1 w_not_actionable=0.01 w_acc=1 reward_clip=20 scaler_clip=5
| reward_scaling=0
| bfs(mean/min/max)=0.6815/0.5360/0.8120 bfs_best=0.1520 bfs_delta_mean=-0.00002 closer/farther=2.9%/2.9% bfs_missing=7.1%
[PPO][end]   step=208000 update_seconds=151.533
[PPO][begin] step=212000 T=4000 terminals=0 (0.00%) reward(mean/std/min/max)=-0.034/0.915/-14.020/+3.999 goal_hits=0 (0.00%) shaper_clip_hits=0 (0.00%) scaler_clip_hits=0 (0.00%)
| eps_clip=0.2 K_epochs=10 mb=64 lr(a/c)=0.0001/0.0002 gamma=0.99 gae_lambda=0.95
| w_progress=100 w_time=0.01 w_damage=0.1 w_not_actionable=0.01 w_acc=1 reward_clip=20 scaler_clip=5
| reward_scaling=0
